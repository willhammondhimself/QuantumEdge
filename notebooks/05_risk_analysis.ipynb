{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantumEdge Tutorial 5: Comprehensive Risk Analysis\n",
    "\n",
    "**Deep Dive into Portfolio Risk Metrics and Monitoring**\n",
    "\n",
    "This notebook provides a comprehensive exploration of portfolio risk analysis, covering traditional and advanced risk metrics, risk decomposition, stress testing, and real-time monitoring techniques. We'll demonstrate how to build a complete risk management framework using QuantumEdge.\n",
    "\n",
    "## Risk Analysis Coverage\n",
    "\n",
    "- **Traditional Risk Metrics**: Volatility, VaR, tracking error, beta analysis\n",
    "- **Advanced Risk Measures**: CVaR, downside deviation, maximum drawdown, tail risk\n",
    "- **Risk Decomposition**: Factor-based risk attribution and contribution analysis\n",
    "- **Stress Testing**: Scenario analysis and Monte Carlo simulation\n",
    "- **Risk Monitoring**: Real-time risk dashboard and alerting systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Risk Framework Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set1\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"QuantumEdge Comprehensive Risk Analysis\")\n",
    "print(\"=\" * 45)\n",
    "print(\"Advanced Portfolio Risk Management and Monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display risk framework overview\n",
    "print(\"\\nüèóÔ∏è RISK MANAGEMENT FRAMEWORK\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "risk_framework = {\n",
    "    \"Level 1 - Basic Risk Metrics\": [\n",
    "        \"‚Ä¢ Standard Deviation (Volatility)\",\n",
    "        \"‚Ä¢ Beta and Correlation Analysis\",\n",
    "        \"‚Ä¢ Sharpe and Information Ratios\",\n",
    "        \"‚Ä¢ Tracking Error and Active Risk\"\n",
    "    ],\n",
    "    \"Level 2 - Distribution-Based Risk\": [\n",
    "        \"‚Ä¢ Value at Risk (VaR) - Historical and Parametric\",\n",
    "        \"‚Ä¢ Conditional Value at Risk (CVaR/Expected Shortfall)\",\n",
    "        \"‚Ä¢ Skewness and Kurtosis Analysis\",\n",
    "        \"‚Ä¢ Downside Deviation and Semi-Variance\"\n",
    "    ],\n",
    "    \"Level 3 - Advanced Risk Measures\": [\n",
    "        \"‚Ä¢ Maximum Drawdown and Recovery Analysis\",\n",
    "        \"‚Ä¢ Tail Risk and Extreme Value Analysis\",\n",
    "        \"‚Ä¢ Risk-Adjusted Performance Metrics\",\n",
    "        \"‚Ä¢ Time-Varying Risk Models\"\n",
    "    ],\n",
    "    \"Level 4 - Risk Decomposition & Attribution\": [\n",
    "        \"‚Ä¢ Factor Risk Decomposition\",\n",
    "        \"‚Ä¢ Asset Contribution to Portfolio Risk\",\n",
    "        \"‚Ä¢ Marginal and Component VaR\",\n",
    "        \"‚Ä¢ Risk Budgeting and Allocation\"\n",
    "    ],\n",
    "    \"Level 5 - Stress Testing & Scenario Analysis\": [\n",
    "        \"‚Ä¢ Historical Scenario Analysis\",\n",
    "        \"‚Ä¢ Monte Carlo Simulation\",\n",
    "        \"‚Ä¢ Stress Testing Framework\",\n",
    "        \"‚Ä¢ Crisis Correlation Analysis\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for level, components in risk_framework.items():\n",
    "    print(f\"\\n{level}:\")\n",
    "    for component in components:\n",
    "        print(f\"  {component}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantumEdge API configuration\n",
    "API_BASE_URL = \"http://localhost:8000/api/v1\"\n",
    "\n",
    "def check_api_health():\n",
    "    \"\"\"Check if QuantumEdge API is running\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL.replace('/api/v1', '')}/health\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ QuantumEdge API is healthy\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå API health check failed: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cannot connect to API: {e}\")\n",
    "        return False\n",
    "\n",
    "api_healthy = check_api_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Portfolio Setup\n",
    "\n",
    "We'll create a diversified portfolio across multiple asset classes and sectors for comprehensive risk analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive asset universe\n",
    "RISK_UNIVERSE = {\n",
    "    # Large Cap Growth\n",
    "    'AAPL': {'name': 'Apple Inc', 'sector': 'Technology', 'type': 'Equity'},\n",
    "    'MSFT': {'name': 'Microsoft Corp', 'sector': 'Technology', 'type': 'Equity'},\n",
    "    'GOOGL': {'name': 'Alphabet Inc', 'sector': 'Technology', 'type': 'Equity'},\n",
    "    \n",
    "    # Value & Cyclical\n",
    "    'JPM': {'name': 'JPMorgan Chase', 'sector': 'Financial', 'type': 'Equity'},\n",
    "    'JNJ': {'name': 'Johnson & Johnson', 'sector': 'Healthcare', 'type': 'Equity'},\n",
    "    'PG': {'name': 'Procter & Gamble', 'sector': 'Consumer', 'type': 'Equity'},\n",
    "    \n",
    "    # High Beta / Growth\n",
    "    'TSLA': {'name': 'Tesla Inc', 'sector': 'Automotive', 'type': 'Equity'},\n",
    "    'NVDA': {'name': 'NVIDIA Corp', 'sector': 'Semiconductors', 'type': 'Equity'},\n",
    "    \n",
    "    # Market Indices\n",
    "    'SPY': {'name': 'S&P 500 ETF', 'sector': 'Market', 'type': 'Index'},\n",
    "    'QQQ': {'name': 'Nasdaq 100 ETF', 'sector': 'Technology', 'type': 'Index'}\n",
    "}\n",
    "\n",
    "SYMBOLS = list(RISK_UNIVERSE.keys())\n",
    "START_DATE = '2019-01-01'  # Longer period for risk analysis\n",
    "END_DATE = '2024-01-01'\n",
    "BENCHMARK = 'SPY'\n",
    "\n",
    "print(f\"Risk Analysis Universe ({len(SYMBOLS)} assets):\")\n",
    "print(\"=\" * 45)\n",
    "for symbol, info in RISK_UNIVERSE.items():\n",
    "    print(f\"{symbol:6} - {info['name']:<25} ({info['sector']}/{info['type']})\")\n",
    "\n",
    "print(f\"\\nAnalysis Period: {START_DATE} to {END_DATE} ({(pd.to_datetime(END_DATE) - pd.to_datetime(START_DATE)).days} days)\")\n",
    "print(f\"Benchmark: {BENCHMARK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download comprehensive market data\n",
    "print(\"Downloading comprehensive market data...\")\n",
    "data = yf.download(SYMBOLS, start=START_DATE, end=END_DATE, progress=False)['Adj Close']\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Separate benchmark\n",
    "benchmark_returns = returns[BENCHMARK]\n",
    "asset_returns = returns.drop(columns=[BENCHMARK])\n",
    "asset_symbols = [s for s in SYMBOLS if s != BENCHMARK]\n",
    "\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"Total observations: {len(returns)}\")\n",
    "print(f\"Assets for analysis: {len(asset_symbols)}\")\n",
    "print(f\"Date range: {returns.index[0].strftime('%Y-%m-%d')} to {returns.index[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Calculate basic statistics\n",
    "annual_returns = asset_returns.mean() * 252\n",
    "annual_volatility = asset_returns.std() * np.sqrt(252)\n",
    "sharpe_ratios = annual_returns / annual_volatility\n",
    "\n",
    "# Calculate market statistics\n",
    "benchmark_annual_return = benchmark_returns.mean() * 252\n",
    "benchmark_annual_vol = benchmark_returns.std() * np.sqrt(252)\n",
    "benchmark_sharpe = benchmark_annual_return / benchmark_annual_vol\n",
    "\n",
    "print(f\"\\nBenchmark ({BENCHMARK}) Statistics:\")\n",
    "print(f\"Annual Return: {benchmark_annual_return:.2%}\")\n",
    "print(f\"Annual Volatility: {benchmark_annual_vol:.2%}\")\n",
    "print(f\"Sharpe Ratio: {benchmark_sharpe:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Level 1: Basic Risk Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_basic_risk_metrics(returns, benchmark_returns):\n",
    "    \"\"\"Calculate comprehensive basic risk metrics\"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    for symbol in returns.columns:\n",
    "        asset_returns = returns[symbol]\n",
    "        \n",
    "        # Basic statistics\n",
    "        annual_return = asset_returns.mean() * 252\n",
    "        annual_vol = asset_returns.std() * np.sqrt(252)\n",
    "        sharpe_ratio = annual_return / annual_vol\n",
    "        \n",
    "        # Beta calculation\n",
    "        covariance = np.cov(asset_returns, benchmark_returns)[0, 1]\n",
    "        benchmark_variance = np.var(benchmark_returns)\n",
    "        beta = covariance / benchmark_variance\n",
    "        \n",
    "        # Alpha calculation\n",
    "        risk_free_rate = 0.02  # Assume 2% risk-free rate\n",
    "        alpha = annual_return - (risk_free_rate + beta * (benchmark_returns.mean() * 252 - risk_free_rate))\n",
    "        \n",
    "        # Correlation\n",
    "        correlation = np.corrcoef(asset_returns, benchmark_returns)[0, 1]\n",
    "        \n",
    "        # Tracking error\n",
    "        active_returns = asset_returns - benchmark_returns\n",
    "        tracking_error = active_returns.std() * np.sqrt(252)\n",
    "        \n",
    "        # Information ratio\n",
    "        information_ratio = (annual_return - benchmark_returns.mean() * 252) / tracking_error if tracking_error > 0 else 0\n",
    "        \n",
    "        metrics[symbol] = {\n",
    "            'Annual Return': annual_return,\n",
    "            'Annual Volatility': annual_vol,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Beta': beta,\n",
    "            'Alpha': alpha,\n",
    "            'Correlation': correlation,\n",
    "            'Tracking Error': tracking_error,\n",
    "            'Information Ratio': information_ratio\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(metrics).T\n",
    "\n",
    "# Calculate basic risk metrics\n",
    "basic_metrics = calculate_basic_risk_metrics(asset_returns, benchmark_returns)\n",
    "\n",
    "print(\"üìä Level 1: Basic Risk Metrics\")\n",
    "print(\"=\" * 35)\n",
    "print(basic_metrics.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize basic risk metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Risk-Return Scatter with Beta sizing\n",
    "scatter = axes[0,0].scatter(basic_metrics['Annual Volatility'], \n",
    "                           basic_metrics['Annual Return'],\n",
    "                           s=basic_metrics['Beta'] * 200,  # Size by beta\n",
    "                           c=basic_metrics['Sharpe Ratio'],\n",
    "                           cmap='viridis', alpha=0.7, edgecolors='black')\n",
    "\n",
    "# Add asset labels\n",
    "for symbol in basic_metrics.index:\n",
    "    axes[0,0].annotate(symbol, \n",
    "                      (basic_metrics.loc[symbol, 'Annual Volatility'], \n",
    "                       basic_metrics.loc[symbol, 'Annual Return']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[0,0].set_xlabel('Annual Volatility')\n",
    "axes[0,0].set_ylabel('Annual Return')\n",
    "axes[0,0].set_title('Risk-Return Profile (Bubble size = Beta)')\n",
    "axes[0,0].grid(True, alpha=0.3)\ncolorbar = plt.colorbar(scatter, ax=axes[0,0])\ncolorbar.set_label('Sharpe Ratio')\n",
    "\n",
    "# 2. Beta Analysis\n",
    "beta_sorted = basic_metrics.sort_values('Beta')\n",
    "colors = ['red' if b < 1 else 'green' for b in beta_sorted['Beta']]\n",
    "bars = axes[0,1].bar(range(len(beta_sorted)), beta_sorted['Beta'], color=colors, alpha=0.7)\n",
    "axes[0,1].set_title('Beta Analysis (Market Sensitivity)')\n",
    "axes[0,1].set_ylabel('Beta')\n",
    "axes[0,1].set_xticks(range(len(beta_sorted)))\n",
    "axes[0,1].set_xticklabels(beta_sorted.index, rotation=45)\n",
    "axes[0,1].axhline(y=1, color='black', linestyle='--', alpha=0.7, label='Market Beta = 1')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, value) in enumerate(zip(bars, beta_sorted['Beta'])):\n",
    "    axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "                  f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Alpha vs Beta Scatter\n",
    "axes[1,0].scatter(basic_metrics['Beta'], basic_metrics['Alpha'], \n",
    "                 s=100, alpha=0.7, c='purple')\n",
    "\n",
    "for symbol in basic_metrics.index:\n",
    "    axes[1,0].annotate(symbol, \n",
    "                      (basic_metrics.loc[symbol, 'Beta'], \n",
    "                       basic_metrics.loc[symbol, 'Alpha']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[1,0].set_xlabel('Beta')\n",
    "axes[1,0].set_ylabel('Alpha')\n",
    "axes[1,0].set_title('Alpha vs Beta Analysis')\n",
    "axes[1,0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,0].axvline(x=1, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Information Ratio Analysis\n",
    "info_ratio_sorted = basic_metrics.sort_values('Information Ratio', ascending=False)\n",
    "colors = ['green' if ir > 0 else 'red' for ir in info_ratio_sorted['Information Ratio']]\n",
    "bars = axes[1,1].bar(range(len(info_ratio_sorted)), info_ratio_sorted['Information Ratio'],\n",
    "                    color=colors, alpha=0.7)\n",
    "axes[1,1].set_title('Information Ratio (Active Return/Tracking Error)')\n",
    "axes[1,1].set_ylabel('Information Ratio')\n",
    "axes[1,1].set_xticks(range(len(info_ratio_sorted)))\n",
    "axes[1,1].set_xticklabels(info_ratio_sorted.index, rotation=45)\n",
    "axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Level 2: Distribution-Based Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distribution_risk_metrics(returns, confidence_levels=[0.01, 0.05, 0.10]):\n",
    "    \"\"\"Calculate VaR, CVaR, and distribution-based risk metrics\"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    for symbol in returns.columns:\n",
    "        asset_returns = returns[symbol]\n",
    "        \n",
    "        # Basic distribution statistics\n",
    "        mean_return = asset_returns.mean() * 252\n",
    "        volatility = asset_returns.std() * np.sqrt(252)\n",
    "        skewness = stats.skew(asset_returns)\n",
    "        kurtosis = stats.kurtosis(asset_returns)\n",
    "        \n",
    "        # Downside metrics\n",
    "        downside_returns = asset_returns[asset_returns < 0]\n",
    "        downside_deviation = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0\n",
    "        semi_variance = np.mean(np.minimum(asset_returns, 0)**2) * 252\n",
    "        \n",
    "        # VaR calculations\n",
    "        var_metrics = {}\n",
    "        cvar_metrics = {}\n",
    "        \n",
    "        for conf in confidence_levels:\n",
    "            # Historical VaR\n",
    "            var_historical = np.percentile(asset_returns, conf * 100) * np.sqrt(252)\n",
    "            \n",
    "            # Parametric VaR (assuming normal distribution)\n",
    "            var_parametric = stats.norm.ppf(conf) * volatility\n",
    "            \n",
    "            # CVaR (Expected Shortfall)\n",
    "            var_threshold = np.percentile(asset_returns, conf * 100)\n",
    "            tail_returns = asset_returns[asset_returns <= var_threshold]\n",
    "            cvar_historical = tail_returns.mean() * np.sqrt(252) if len(tail_returns) > 0 else var_historical\n",
    "            \n",
    "            var_metrics[f'VaR_{int(conf*100)}%'] = var_historical\n",
    "            var_metrics[f'VaR_Param_{int(conf*100)}%'] = var_parametric\n",
    "            cvar_metrics[f'CVaR_{int(conf*100)}%'] = cvar_historical\n",
    "        \n",
    "        # Compile all metrics\n",
    "        asset_metrics = {\n",
    "            'Mean Return': mean_return,\n",
    "            'Volatility': volatility,\n",
    "            'Skewness': skewness,\n",
    "            'Kurtosis': kurtosis,\n",
    "            'Downside Deviation': downside_deviation,\n",
    "            'Semi-Variance': semi_variance,\n",
    "            **var_metrics,\n",
    "            **cvar_metrics\n",
    "        }\n",
    "        \n",
    "        metrics[symbol] = asset_metrics\n",
    "    \n",
    "    return pd.DataFrame(metrics).T\n",
    "\n",
    "# Calculate distribution-based risk metrics\n",
    "distribution_metrics = calculate_distribution_risk_metrics(asset_returns)\n",
    "\n",
    "print(\"üìà Level 2: Distribution-Based Risk Metrics\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Display key metrics\n",
    "key_dist_metrics = ['Mean Return', 'Volatility', 'Skewness', 'Kurtosis', \n",
    "                   'VaR_5%', 'CVaR_5%', 'Downside Deviation']\n",
    "print(distribution_metrics[key_dist_metrics].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution-based risk metrics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Skewness vs Kurtosis\n",
    "axes[0,0].scatter(distribution_metrics['Skewness'], distribution_metrics['Kurtosis'],\n",
    "                 s=100, alpha=0.7, c='blue')\n",
    "\n",
    "for symbol in distribution_metrics.index:\n",
    "    axes[0,0].annotate(symbol, \n",
    "                      (distribution_metrics.loc[symbol, 'Skewness'], \n",
    "                       distribution_metrics.loc[symbol, 'Kurtosis']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[0,0].set_xlabel('Skewness')\n",
    "axes[0,0].set_ylabel('Kurtosis')\n",
    "axes[0,0].set_title('Return Distribution Shape')\n",
    "axes[0,0].axhline(y=0, color='black', linestyle='--', alpha=0.5, label='Normal Kurtosis')\n",
    "axes[0,0].axvline(x=0, color='black', linestyle='--', alpha=0.5, label='Zero Skewness')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. VaR Comparison (Historical vs Parametric)\n",
    "var_comparison = distribution_metrics[['VaR_5%', 'VaR_Param_5%']].abs()  # Make positive\n",
    "x = np.arange(len(var_comparison))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,1].bar(x - width/2, var_comparison['VaR_5%'], width, \n",
    "             label='Historical VaR', alpha=0.7, color='red')\n",
    "axes[0,1].bar(x + width/2, var_comparison['VaR_Param_5%'], width, \n",
    "             label='Parametric VaR', alpha=0.7, color='orange')\n",
    "\n",
    "axes[0,1].set_title('VaR Comparison (5% Confidence)')\n",
    "axes[0,1].set_ylabel('VaR (Absolute)')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(var_comparison.index, rotation=45)\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. CVaR Analysis\n",
    "cvar_data = distribution_metrics[['CVaR_1%', 'CVaR_5%', 'CVaR_10%']].abs()\n",
    "cvar_data.mean().plot(kind='bar', ax=axes[0,2], color='darkred', alpha=0.7)\n",
    "axes[0,2].set_title('Average CVaR by Confidence Level')\n",
    "axes[0,2].set_ylabel('CVaR (Absolute)')\n",
    "axes[0,2].set_xlabel('Confidence Level')\n",
    "axes[0,2].tick_params(axis='x', rotation=0)\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Volatility vs Downside Deviation\n",
    "axes[1,0].scatter(distribution_metrics['Volatility'], \n",
    "                 distribution_metrics['Downside Deviation'],\n",
    "                 s=100, alpha=0.7, c='green')\n,
    "\n",
    "# Add diagonal line\n",
    "max_vol = max(distribution_metrics['Volatility'].max(), \n",
    "              distribution_metrics['Downside Deviation'].max())\n",
    "axes[1,0].plot([0, max_vol], [0, max_vol], 'r--', alpha=0.5, label='Equal Risk')\n",
    "\n",
    "for symbol in distribution_metrics.index:\n",
    "    axes[1,0].annotate(symbol, \n",
    "                      (distribution_metrics.loc[symbol, 'Volatility'], \n",
    "                       distribution_metrics.loc[symbol, 'Downside Deviation']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[1,0].set_xlabel('Total Volatility')\n",
    "axes[1,0].set_ylabel('Downside Deviation')\n",
    "axes[1,0].set_title('Total vs Downside Risk')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Tail Risk Heat Map\n",
    "tail_risk_cols = ['VaR_1%', 'VaR_5%', 'CVaR_1%', 'CVaR_5%']\n",
    "tail_risk_data = distribution_metrics[tail_risk_cols].abs()\n",
    "\n",
    "sns.heatmap(tail_risk_data.T, annot=True, fmt='.3f', cmap='Reds', \n",
    "           ax=axes[1,1], cbar_kws={'label': 'Risk Level'})\n",
    "axes[1,1].set_title('Tail Risk Heat Map')\n",
    "axes[1,1].set_xlabel('Assets')\n",
    "axes[1,1].set_ylabel('Risk Metrics')\n",
    "\n",
    "# 6. Return Distribution Examples (for selected assets)\n",
    "selected_assets = ['AAPL', 'TSLA', 'JNJ']  # Different risk profiles\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i, (asset, color) in enumerate(zip(selected_assets, colors)):\n",
    "    if asset in asset_returns.columns:\n",
    "        asset_rets = asset_returns[asset] * 100  # Convert to percentage\n",
    "        axes[1,2].hist(asset_rets, bins=50, alpha=0.6, color=color, \n",
    "                      label=f'{asset}', density=True)\n",
    "\n",
    "axes[1,2].set_xlabel('Daily Returns (%)')\n",
    "axes[1,2].set_ylabel('Density')\n",
    "axes[1,2].set_title('Return Distribution Comparison')\n",
    "axes[1,2].legend()\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Level 3: Advanced Risk Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_advanced_risk_metrics(returns, prices):\n",
    "    \"\"\"Calculate advanced risk metrics including drawdown analysis\"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    for symbol in returns.columns:\n",
    "        asset_returns = returns[symbol]\n",
    "        asset_prices = prices[symbol]\n",
    "        \n",
    "        # Cumulative returns for drawdown calculation\n",
    "        cumulative_returns = (1 + asset_returns).cumprod()\n",
    "        running_max = cumulative_returns.expanding().max()\n",
    "        drawdowns = (cumulative_returns - running_max) / running_max\n",
    "        \n",
    "        # Drawdown metrics\n",
    "        max_drawdown = drawdowns.min()\n",
    "        max_dd_duration = 0\n",
    "        current_dd_duration = 0\n",
    "        \n",
    "        # Calculate drawdown duration\n",
    "        for dd in drawdowns:\n",
    "            if dd < 0:\n",
    "                current_dd_duration += 1\n",
    "                max_dd_duration = max(max_dd_duration, current_dd_duration)\n",
    "            else:\n",
    "                current_dd_duration = 0\n",
    "        \n",
    "        # Recovery analysis\n",
    "        drawdown_periods = []\n",
    "        in_drawdown = False\n",
    "        start_idx = 0\n",
    "        \n",
    "        for i, dd in enumerate(drawdowns):\n",
    "            if dd < -0.05 and not in_drawdown:  # Start of significant drawdown (>5%)\n",
    "                in_drawdown = True\n",
    "                start_idx = i\n",
    "            elif dd >= 0 and in_drawdown:  # Recovery\n",
    "                in_drawdown = False\n",
    "                drawdown_periods.append(i - start_idx)\n",
    "        \n",
    "        avg_recovery_time = np.mean(drawdown_periods) if drawdown_periods else 0\n",
    "        \n",
    "        # Calmar ratio\n",
    "        annual_return = asset_returns.mean() * 252\n",
    "        calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "        \n",
    "        # Sortino ratio\n",
    "        downside_returns = asset_returns[asset_returns < 0]\n",
    "        downside_std = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0\n",
    "        sortino_ratio = (annual_return - 0.02) / downside_std if downside_std > 0 else 0\n",
    "        \n",
    "        # Tail ratio (95th percentile / 5th percentile)\n",
    "        tail_ratio = np.percentile(asset_returns, 95) / abs(np.percentile(asset_returns, 5))\n",
    "        \n",
    "        # Upside/Downside capture ratios vs benchmark\n",
    "        benchmark_up = benchmark_returns[benchmark_returns > 0]\n",
    "        benchmark_down = benchmark_returns[benchmark_returns < 0]\n",
    "        \n",
    "        asset_up = asset_returns[benchmark_returns > 0]\n",
    "        asset_down = asset_returns[benchmark_returns < 0]\n",
    "        \n",
    "        upside_capture = (asset_up.mean() / benchmark_up.mean()) if len(benchmark_up) > 0 else 0\n",
    "        downside_capture = (asset_down.mean() / benchmark_down.mean()) if len(benchmark_down) > 0 else 0\n",
    "        \n",
    "        metrics[symbol] = {\n",
    "            'Max Drawdown': max_drawdown,\n",
    "            'Max DD Duration (days)': max_dd_duration,\n",
    "            'Avg Recovery Time (days)': avg_recovery_time,\n",
    "            'Calmar Ratio': calmar_ratio,\n",
    "            'Sortino Ratio': sortino_ratio,\n",
    "            'Tail Ratio': tail_ratio,\n",
    "            'Upside Capture': upside_capture,\n",
    "            'Downside Capture': downside_capture,\n",
    "            'Current Drawdown': drawdowns.iloc[-1]  # Latest drawdown\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(metrics).T\n",
    "\n",
    "# Calculate advanced risk metrics\n",
    "advanced_metrics = calculate_advanced_risk_metrics(asset_returns, data.drop(columns=[BENCHMARK]))\n",
    "\n",
    "print(\"üöÄ Level 3: Advanced Risk Measures\")\n",
    "print(\"=\" * 40)\n",
    "print(advanced_metrics.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize advanced risk metrics\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "\n",
    "# 1. Drawdown Analysis\n",
    "max_dd_abs = abs(advanced_metrics['Max Drawdown'])\n",
    "colors = plt.cm.Reds(max_dd_abs / max_dd_abs.max())\n",
    "bars = axes[0,0].bar(advanced_metrics.index, max_dd_abs, color=colors, alpha=0.8)\n",
    "axes[0,0].set_title('Maximum Drawdown by Asset')\n",
    "axes[0,0].set_ylabel('Maximum Drawdown')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, max_dd_abs):\n",
    "    axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                  f'{value:.1%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Risk-Adjusted Performance Ratios\n",
    "ratios_data = advanced_metrics[['Calmar Ratio', 'Sortino Ratio']]\n",
    "x = np.arange(len(ratios_data))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,1].bar(x - width/2, ratios_data['Calmar Ratio'], width, \n",
    "             label='Calmar', alpha=0.7, color='blue')\n",
    "axes[0,1].bar(x + width/2, ratios_data['Sortino Ratio'], width, \n",
    "             label='Sortino', alpha=0.7, color='green')\n",
    "\n",
    "axes[0,1].set_title('Advanced Risk-Adjusted Ratios')\n",
    "axes[0,1].set_ylabel('Ratio Value')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(ratios_data.index, rotation=45)\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Drawdown Duration vs Recovery Time\n",
    "axes[1,0].scatter(advanced_metrics['Max DD Duration (days)'], \n",
    "                 advanced_metrics['Avg Recovery Time (days)'],\n",
    "                 s=max_dd_abs * 1000, alpha=0.6, c='red')\n",
    "\n",
    "for symbol in advanced_metrics.index:\n",
    "    axes[1,0].annotate(symbol, \n",
    "                      (advanced_metrics.loc[symbol, 'Max DD Duration (days)'], \n",
    "                       advanced_metrics.loc[symbol, 'Avg Recovery Time (days)']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[1,0].set_xlabel('Max Drawdown Duration (days)')\n",
    "axes[1,0].set_ylabel('Average Recovery Time (days)')\n",
    "axes[1,0].set_title('Drawdown Duration vs Recovery (Bubble size = Max DD)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Upside vs Downside Capture\n",
    "axes[1,1].scatter(advanced_metrics['Upside Capture'], \n",
    "                 advanced_metrics['Downside Capture'],\n",
    "                 s=100, alpha=0.7, c='purple')\n",
    "\n",
    "# Add quadrant lines\n",
    "axes[1,1].axhline(y=1, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1,1].axvline(x=1, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add quadrant labels\n",
    "axes[1,1].text(0.5, 1.3, 'Low Up\\nHigh Down', ha='center', va='center', \n",
    "              bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
    "axes[1,1].text(1.3, 1.3, 'High Up\\nHigh Down', ha='center', va='center',\n",
    "              bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "axes[1,1].text(1.3, 0.5, 'High Up\\nLow Down', ha='center', va='center',\n",
    "              bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "axes[1,1].text(0.5, 0.5, 'Low Up\\nLow Down', ha='center', va='center',\n",
    "              bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "\n",
    "for symbol in advanced_metrics.index:\n",
    "    axes[1,1].annotate(symbol, \n",
    "                      (advanced_metrics.loc[symbol, 'Upside Capture'], \n",
    "                       advanced_metrics.loc[symbol, 'Downside Capture']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[1,1].set_xlabel('Upside Capture Ratio')\n",
    "axes[1,1].set_ylabel('Downside Capture Ratio')\n",
    "axes[1,1].set_title('Market Capture Analysis')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Current Drawdown Status\n",
    "current_dd = advanced_metrics['Current Drawdown']\n",
    "colors = ['red' if dd < -0.05 else 'yellow' if dd < 0 else 'green' for dd in current_dd]\n",
    "bars = axes[2,0].bar(advanced_metrics.index, abs(current_dd), color=colors, alpha=0.7)\n",
    "axes[2,0].set_title('Current Drawdown Status')\n",
    "axes[2,0].set_ylabel('Current Drawdown')\n",
    "axes[2,0].tick_params(axis='x', rotation=45)\n",
    "axes[2,0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[2,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='red', alpha=0.7, label='Significant DD (>5%)'),\n",
    "                  Patch(facecolor='yellow', alpha=0.7, label='Minor DD (0-5%)'),\n",
    "                  Patch(facecolor='green', alpha=0.7, label='At Peak')]\n",
    "axes[2,0].legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# 6. Tail Risk Analysis\n",
    "tail_ratios = advanced_metrics['Tail Ratio']\n",
    "bars = axes[2,1].bar(advanced_metrics.index, tail_ratios, \n",
    "                    color='darkblue', alpha=0.7)\n",
    "axes[2,1].set_title('Tail Ratio (95th/5th Percentile)')\n",
    "axes[2,1].set_ylabel('Tail Ratio')\n",
    "axes[2,1].tick_params(axis='x', rotation=45)\n",
    "axes[2,1].axhline(y=1, color='red', linestyle='--', alpha=0.7, \n",
    "                 label='Symmetric Distribution')\n",
    "axes[2,1].legend()\n",
    "axes[2,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Portfolio Risk Analysis using QuantumEdge\n",
    "\n",
    "Now let's create optimized portfolios and analyze their risk characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_risk_optimized_portfolios():\n",
    "    \"\"\"Create portfolios optimized for different risk objectives\"\"\"\n",
    "    \n",
    "    if not api_healthy:\n",
    "        print(\"‚ùå API not available - creating sample portfolios\")\n",
    "        # Create sample portfolios for demonstration\n",
    "        return {\n",
    "            'Equal Weight': np.ones(len(asset_symbols)) / len(asset_symbols),\n",
    "            'Low Volatility': np.array([0.3, 0.25, 0.2, 0.1, 0.05, 0.05, 0.03, 0.02]),\n",
    "            'High Return': np.array([0.05, 0.1, 0.15, 0.2, 0.25, 0.25, 0.0, 0.0])\n",
    "        }\n",
    "    \n",
    "    portfolios = {}\n",
    "    \n",
    "    # Prepare data for optimization\n",
    "    expected_returns = asset_returns.mean().values * 252\n",
    "    cov_matrix = asset_returns.cov().values * 252\n",
    "    returns_data = asset_returns.values\n",
    "    \n",
    "    # Define optimization strategies\n",
    "    strategies = {\n",
    "        'Min Variance': {'objective': 'minimize_variance'},\n",
    "        'Max Sharpe': {'objective': 'maximize_sharpe'},\n",
    "        'Min CVaR': {'objective': 'minimize_cvar', 'cvar_confidence': 0.05},\n",
    "        'Max Calmar': {'objective': 'maximize_calmar', 'lookback_periods': 252}\n",
    "    }\n",
    "    \n",
    "    print(\"üîß Creating Risk-Optimized Portfolios...\")\n",
    "    \n",
    "    for name, params in strategies.items():\n",
    "        print(f\"\\nOptimizing {name} portfolio...\")\n",
    "        \n",
    "        payload = {\n",
    "            \"expected_returns\": expected_returns.tolist(),\n",
    "            \"covariance_matrix\": cov_matrix.tolist(),\n",
    "            \"risk_aversion\": 1.0,\n",
    "            **params\n",
    "        }\n",
    "        \n",
    "        # Add historical returns for advanced objectives\n",
    "        if params['objective'] in ['minimize_cvar', 'maximize_calmar']:\n",
    "            payload[\"returns_data\"] = returns_data.tolist()\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(f\"{API_BASE_URL}/optimize/mean-variance\", json=payload)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if result['success']:\n",
    "                    portfolios[name] = np.array(result['portfolio']['weights'])\n",
    "                    print(f\"‚úÖ Success - Sharpe: {result['portfolio']['sharpe_ratio']:.3f}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Optimization failed\")\n",
    "            else:\n",
    "                print(f\"‚ùå API request failed: {response.status_code}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "        \n",
    "        time.sleep(1)  # Rate limiting\n",
    "    \n",
    "    # Add equal weight portfolio for comparison\n",
    "    portfolios['Equal Weight'] = np.ones(len(asset_symbols)) / len(asset_symbols)\n",
    "    \n",
    "    return portfolios\n",
    "\n",
    "# Create optimized portfolios\n",
    "risk_portfolios = create_risk_optimized_portfolios()\n",
    "print(f\"\\nüìä Created {len(risk_portfolios)} risk-optimized portfolios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_portfolio_risk(portfolios, returns, benchmark_returns):\n",
    "    \"\"\"Comprehensive risk analysis of portfolios\"\"\"\n",
    "    \n",
    "    portfolio_metrics = {}\n",
    "    \n",
    "    for name, weights in portfolios.items():\n",
    "        # Ensure weights sum to 1 and match returns columns\n",
    "        if len(weights) != len(returns.columns):\n",
    "            weights = weights[:len(returns.columns)]  # Truncate if too long\n",
    "            weights = weights / weights.sum()  # Renormalize\n",
    "        \n",
    "        # Calculate portfolio returns\n",
    "        portfolio_returns = (returns * weights).sum(axis=1)\n",
    "        \n",
    "        # Basic metrics\n",
    "        annual_return = portfolio_returns.mean() * 252\n",
    "        annual_vol = portfolio_returns.std() * np.sqrt(252)\n",
    "        sharpe_ratio = annual_return / annual_vol\n",
    "        \n",
    "        # Risk metrics\n",
    "        var_5 = np.percentile(portfolio_returns, 5) * np.sqrt(252)\n",
    "        cvar_5 = portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 5)].mean() * np.sqrt(252)\n",
    "        \n",
    "        # Drawdown analysis\n",
    "        cumulative = (1 + portfolio_returns).cumprod()\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdowns = (cumulative - running_max) / running_max\n",
    "        max_drawdown = drawdowns.min()\n",
    "        \n",
    "        # Beta vs benchmark\n",
    "        covariance = np.cov(portfolio_returns, benchmark_returns)[0, 1]\n",
    "        benchmark_variance = np.var(benchmark_returns)\n",
    "        beta = covariance / benchmark_variance\n",
    "        \n",
    "        # Tracking error\n",
    "        active_returns = portfolio_returns - benchmark_returns\n",
    "        tracking_error = active_returns.std() * np.sqrt(252)\n",
    "        \n",
    "        # Advanced ratios\n",
    "        calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "        \n",
    "        downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "        sortino_ratio = (annual_return - 0.02) / (downside_returns.std() * np.sqrt(252)) if len(downside_returns) > 0 else 0\n",
    "        \n",
    "        # Portfolio concentration\n",
    "        herfindahl_index = np.sum(weights**2)\n",
    "        effective_assets = 1 / herfindahl_index\n",
    "        max_weight = np.max(weights)\n",
    "        \n",
    "        portfolio_metrics[name] = {\n",
    "            'Annual Return': annual_return,\n",
    "            'Annual Volatility': annual_vol,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Sortino Ratio': sortino_ratio,\n",
    "            'Calmar Ratio': calmar_ratio,\n",
    "            'Beta': beta,\n",
    "            'VaR (5%)': var_5,\n",
    "            'CVaR (5%)': cvar_5,\n",
    "            'Max Drawdown': max_drawdown,\n",
    "            'Tracking Error': tracking_error,\n",
    "            'Max Weight': max_weight,\n",
    "            'Effective Assets': effective_assets,\n",
    "            'Herfindahl Index': herfindahl_index\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(portfolio_metrics).T\n",
    "\n",
    "# Analyze portfolio risk\n",
    "portfolio_risk_analysis = analyze_portfolio_risk(risk_portfolios, asset_returns, benchmark_returns)\n",
    "\n",
    "print(\"\\nüéØ Portfolio Risk Analysis Results:\")\n",
    "print(\"=\" * 45)\n",
    "print(portfolio_risk_analysis.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio risk comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Risk-Return Scatter\n",
    "scatter = axes[0,0].scatter(portfolio_risk_analysis['Annual Volatility'], \n",
    "                           portfolio_risk_analysis['Annual Return'],\n",
    "                           s=200, alpha=0.7, c=portfolio_risk_analysis['Sharpe Ratio'],\n",
    "                           cmap='viridis', edgecolors='black')\n",
    "\n",
    "for portfolio in portfolio_risk_analysis.index:\n",
    "    axes[0,0].annotate(portfolio, \n",
    "                      (portfolio_risk_analysis.loc[portfolio, 'Annual Volatility'], \n",
    "                       portfolio_risk_analysis.loc[portfolio, 'Annual Return']),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "axes[0,0].set_xlabel('Annual Volatility')\n",
    "axes[0,0].set_ylabel('Annual Return')\n",
    "axes[0,0].set_title('Portfolio Risk-Return Profile')\n",
    "axes[0,0].grid(True, alpha=0.3)\nplt.colorbar(scatter, ax=axes[0,0], label='Sharpe Ratio')\n",
    "\n",
    "# 2. Risk-Adjusted Performance Ratios\n",
    "ratios = ['Sharpe Ratio', 'Sortino Ratio', 'Calmar Ratio']\n",
    "x = np.arange(len(portfolio_risk_analysis))\n",
    "width = 0.25\n",
    "\n",
    "for i, ratio in enumerate(ratios):\n",
    "    axes[0,1].bar(x + i*width - width, portfolio_risk_analysis[ratio], \n",
    "                 width, label=ratio, alpha=0.7)\n",
    "\n",
    "axes[0,1].set_title('Risk-Adjusted Performance Ratios')\n",
    "axes[0,1].set_ylabel('Ratio Value')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(portfolio_risk_analysis.index, rotation=45)\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Tail Risk Comparison\n",
    "tail_risks = portfolio_risk_analysis[['VaR (5%)', 'CVaR (5%)']].abs()\n",
    "tail_risks.plot(kind='bar', ax=axes[0,2], alpha=0.7)\n",
    "axes[0,2].set_title('Tail Risk Comparison')\n",
    "axes[0,2].set_ylabel('Risk Level')\n",
    "axes[0,2].tick_params(axis='x', rotation=45)\n",
    "axes[0,2].legend()\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Maximum Drawdown Analysis\n",
    "max_dd_abs = abs(portfolio_risk_analysis['Max Drawdown'])\n",
    "colors = plt.cm.Reds(max_dd_abs / max_dd_abs.max())\n",
    "bars = axes[1,0].bar(portfolio_risk_analysis.index, max_dd_abs, \n",
    "                    color=colors, alpha=0.8)\n",
    "axes[1,0].set_title('Maximum Drawdown by Portfolio')\n",
    "axes[1,0].set_ylabel('Maximum Drawdown')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Portfolio Concentration\n",
    "concentration_data = portfolio_risk_analysis[['Max Weight', 'Effective Assets']]\n",
    "ax_twin = axes[1,1].twinx()\n",
    "\n",
    "bars1 = axes[1,1].bar(x - width/2, concentration_data['Max Weight'], \n",
    "                     width, alpha=0.7, color='red', label='Max Weight')\n",
    "bars2 = ax_twin.bar(x + width/2, concentration_data['Effective Assets'], \n",
    "                   width, alpha=0.7, color='blue', label='Effective Assets')\n",
    "\n",
    "axes[1,1].set_title('Portfolio Concentration Analysis')\n",
    "axes[1,1].set_ylabel('Max Weight', color='red')\n",
    "ax_twin.set_ylabel('Effective Assets', color='blue')\n",
    "axes[1,1].set_xticks(x)\n",
    "axes[1,1].set_xticklabels(portfolio_risk_analysis.index, rotation=45)\n",
    "axes[1,1].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Portfolio Weights Heatmap\n",
    "weights_matrix = np.array([weights for weights in risk_portfolios.values()])\n",
    "portfolio_names = list(risk_portfolios.keys())\n",
    "weights_df = pd.DataFrame(weights_matrix, \n",
    "                         index=portfolio_names, \n",
    "                         columns=asset_symbols)\n",
    "\n",
    "sns.heatmap(weights_df, annot=True, fmt='.2f', cmap='Blues', \n",
    "           ax=axes[1,2], cbar_kws={'label': 'Weight'})\n",
    "axes[1,2].set_title('Portfolio Weights Heatmap')\n",
    "axes[1,2].set_xlabel('Assets')\n",
    "axes[1,2].set_ylabel('Portfolios')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Risk Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_risk_monitoring_dashboard(portfolio_metrics, asset_metrics):\n",
    "    \"\"\"Create a comprehensive risk monitoring dashboard\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä QUANTUMEDGE RISK MONITORING DASHBOARD\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Current market conditions\n",
    "    print(\"\\nüåç MARKET ENVIRONMENT ANALYSIS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Calculate market regime indicators\n",
    "    recent_returns = asset_returns.tail(22)  # Last month\n",
    "    market_vol = recent_returns.std().mean() * np.sqrt(252)\n",
    "    market_correlation = recent_returns.corr().mean().mean()\n",
    "    \n",
    "    regime_indicators = {\n",
    "        'Market Volatility': market_vol,\n",
    "        'Average Correlation': market_correlation,\n",
    "        'VIX Proxy': benchmark_returns.tail(22).std() * np.sqrt(252)\n",
    "    }\n",
    "    \n",
    "    for indicator, value in regime_indicators.items():\n",
    "        if indicator == 'Average Correlation':\n",
    "            status = \"üî¥ HIGH\" if value > 0.7 else \"üü° MEDIUM\" if value > 0.5 else \"üü¢ LOW\"\n",
    "            print(f\"{indicator}: {value:.3f} {status}\")\n",
    "        else:\n",
    "            status = \"üî¥ HIGH\" if value > 0.25 else \"üü° MEDIUM\" if value > 0.15 else \"üü¢ LOW\"\n",
    "            print(f\"{indicator}: {value:.2%} {status}\")\n",
    "    \n",
    "    # Portfolio risk alerts\n",
    "    print(\"\\nüö® PORTFOLIO RISK ALERTS\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    alerts = []\n",
    "    \n",
    "    for portfolio in portfolio_metrics.index:\n",
    "        metrics = portfolio_metrics.loc[portfolio]\n",
    "        \n",
    "        # Check risk thresholds\n",
    "        if abs(metrics['Max Drawdown']) > 0.20:\n",
    "            alerts.append(f\"‚ö†Ô∏è {portfolio}: High drawdown risk ({metrics['Max Drawdown']:.1%})\")\n",
    "        \n",
    "        if abs(metrics['VaR (5%)']) > 0.15:\n",
    "            alerts.append(f\"‚ö†Ô∏è {portfolio}: High VaR ({metrics['VaR (5%)']:.1%})\")\n",
    "        \n",
    "        if metrics['Max Weight'] > 0.40:\n",
    "            alerts.append(f\"‚ö†Ô∏è {portfolio}: High concentration ({metrics['Max Weight']:.1%})\")\n",
    "        \n",
    "        if metrics['Tracking Error'] > 0.10:\n",
    "            alerts.append(f\"‚ö†Ô∏è {portfolio}: High tracking error ({metrics['Tracking Error']:.1%})\")\n",
    "    \n",
    "    if alerts:\n",
    "        for alert in alerts:\n",
    "            print(alert)\n",
    "    else:\n",
    "        print(\"‚úÖ No active risk alerts\")\n",
    "    \n",
    "    # Asset-level risk warnings\n",
    "    print(\"\\nüìà ASSET-LEVEL RISK WARNINGS\")\n",
    "    print(\"-\" * 28)\n",
    "    \n",
    "    asset_alerts = []\n",
    "    \n",
    "    for asset in asset_metrics.index:\n",
    "        metrics = asset_metrics.loc[asset]\n",
    "        \n",
    "        if abs(metrics['Current Drawdown']) > 0.15:\n",
    "            asset_alerts.append(f\"üî¥ {asset}: In significant drawdown ({metrics['Current Drawdown']:.1%})\")\n",
    "        elif abs(metrics['Current Drawdown']) > 0.10:\n",
    "            asset_alerts.append(f\"üü° {asset}: Moderate drawdown ({metrics['Current Drawdown']:.1%})\")\n",
    "        \n",
    "        if metrics['Max DD Duration (days)'] > 100:\n",
    "            asset_alerts.append(f\"‚è∞ {asset}: Extended drawdown period ({metrics['Max DD Duration (days)']:.0f} days)\")\n",
    "    \n",
    "    if asset_alerts:\n",
    "        for alert in asset_alerts[:5]:  # Limit to top 5\n",
    "            print(alert)\n",
    "    else:\n",
    "        print(\"‚úÖ No significant asset-level warnings\")\n",
    "    \n",
    "    # Risk ranking\n",
    "    print(\"\\nüèÜ PORTFOLIO RISK RANKINGS\")\n",
    "    print(\"-\" * 26)\n",
    "    \n",
    "    rankings = {\n",
    "        'Lowest Risk (Volatility)': portfolio_metrics.nsmallest(3, 'Annual Volatility').index.tolist(),\n",
    "        'Best Risk-Adjusted (Sharpe)': portfolio_metrics.nlargest(3, 'Sharpe Ratio').index.tolist(),\n",
    "        'Lowest Drawdown': portfolio_metrics.nsmallest(3, lambda x: abs(x['Max Drawdown'])).index.tolist(),\n",
    "        'Best Tail Risk (CVaR)': portfolio_metrics.nsmallest(3, lambda x: abs(x['CVaR (5%)'])).index.tolist()\n",
    "    }\n",
    "    \n",
    "    for category, top_portfolios in rankings.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for i, portfolio in enumerate(top_portfolios, 1):\n",
    "            print(f\"  {i}. {portfolio}\")\n",
    "    \n",
    "    # Performance attribution\n",
    "    print(\"\\nüìä RISK CONTRIBUTION ANALYSIS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Find the portfolio with highest Sharpe for detailed analysis\n",
    "    best_portfolio = portfolio_metrics['Sharpe Ratio'].idxmax()\n",
    "    best_weights = risk_portfolios[best_portfolio]\n",
    "    \n",
    "    print(f\"\\nDetailed Analysis: {best_portfolio} Portfolio\")\n",
    "    \n",
    "    # Calculate risk contributions\n",
    "    portfolio_vol = portfolio_metrics.loc[best_portfolio, 'Annual Volatility']\n",
    "    cov_matrix = asset_returns.cov().values * 252\n",
    "    \n",
    "    # Marginal contributions to risk\n",
    "    marginal_contrib = np.dot(cov_matrix, best_weights) / portfolio_vol\n",
    "    risk_contrib = best_weights * marginal_contrib\n",
    "    risk_contrib_pct = risk_contrib / risk_contrib.sum()\n",
    "    \n",
    "    print(\"\\nRisk Contribution by Asset:\")\n",
    "    for i, (asset, contrib) in enumerate(zip(asset_symbols, risk_contrib_pct)):\n",
    "        if best_weights[i] > 0.01:  # Only show significant positions\n",
    "            print(f\"  {asset}: {contrib:.1%} (Weight: {best_weights[i]:.1%})\")\n",
    "    \n",
    "    return regime_indicators, alerts, asset_alerts\n",
    "\n",
    "# Create risk monitoring dashboard\n",
    "regime_data, portfolio_alerts, asset_alerts = create_risk_monitoring_dashboard(\n",
    "    portfolio_risk_analysis, advanced_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Stress Testing and Scenario Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_stress_testing(portfolios, returns):\n",
    "    \"\"\"Perform comprehensive stress testing and scenario analysis\"\"\"\n",
    "    \n",
    "    print(\"\\nüî¨ STRESS TESTING & SCENARIO ANALYSIS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Define stress scenarios\n",
    "    scenarios = {\n",
    "        'Market Crash (-20%)': {\n",
    "            'description': 'Broad market decline of 20%',\n",
    "            'shocks': {symbol: -0.20 for symbol in asset_symbols}\n",
    "        },\n",
    "        'Tech Selloff (-30%)': {\n",
    "            'description': 'Technology sector crash',\n",
    "            'shocks': {\n",
    "                'AAPL': -0.30, 'MSFT': -0.30, 'GOOGL': -0.35, 'NVDA': -0.40,\n",
    "                'JPM': -0.10, 'JNJ': -0.10, 'PG': -0.05, 'TSLA': -0.25, 'QQQ': -0.35\n",
    "            }\n",
    "        },\n",
    "        'Interest Rate Shock (+300bp)': {\n",
    "            'description': 'Sharp interest rate increase',\n",
    "            'shocks': {\n",
    "                'AAPL': -0.15, 'MSFT': -0.15, 'GOOGL': -0.18, 'NVDA': -0.20,\n",
    "                'JPM': 0.05, 'JNJ': -0.08, 'PG': -0.08, 'TSLA': -0.25, 'QQQ': -0.18\n",
    "            }\n",
    "        },\n",
    "        'Volatility Spike (+50%)': {\n",
    "            'description': 'Market volatility increases by 50%',\n",
    "            'vol_multiplier': 1.5\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    stress_results = {}\n",
    "    \n",
    "    for scenario_name, scenario in scenarios.items():\n",
    "        print(f\"\\nüìâ {scenario_name}\")\n",
    "        print(f\"    {scenario['description']}\")\n",
    "        \n",
    "        scenario_results = {}\n",
    "        \n",
    "        for portfolio_name, weights in portfolios.items():\n",
    "            if len(weights) != len(asset_symbols):\n",
    "                weights = weights[:len(asset_symbols)]\n",
    "                weights = weights / weights.sum()\n",
    "            \n",
    "            if 'shocks' in scenario:\n",
    "                # Direct shock scenario\n",
    "                portfolio_shock = sum(weights[i] * scenario['shocks'].get(asset_symbols[i], 0) \n",
    "                                    for i in range(len(weights)))\n",
    "                scenario_results[portfolio_name] = portfolio_shock\n",
    "            \n",
    "            elif 'vol_multiplier' in scenario:\n",
    "                # Volatility shock scenario\n",
    "                portfolio_returns = (returns * weights).sum(axis=1)\n",
    "                current_vol = portfolio_returns.std() * np.sqrt(252)\n",
    "                stressed_vol = current_vol * scenario['vol_multiplier']\n",
    "                vol_impact = stressed_vol - current_vol\n",
    "                scenario_results[portfolio_name] = -vol_impact  # Negative impact\n",
    "        \n",
    "        stress_results[scenario_name] = scenario_results\n",
    "        \n",
    "        # Display results\n",
    "        for portfolio, impact in scenario_results.items():\n",
    "            print(f\"    {portfolio}: {impact:.2%}\")\n",
    "    \n",
    "    return stress_results\n",
    "\n",
    "# Perform stress testing\n",
    "stress_test_results = perform_stress_testing(risk_portfolios, asset_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stress test results\n",
    "stress_df = pd.DataFrame(stress_test_results)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Stress Test Heatmap\n",
    "sns.heatmap(stress_df, annot=True, fmt='.2%', cmap='RdYlGn_r', center=0,\n",
    "           ax=axes[0,0], cbar_kws={'label': 'Impact (%)'})axes[0,0].set_title('Stress Test Results Heatmap')\n",
    "axes[0,0].set_xlabel('Stress Scenarios')\n",
    "axes[0,0].set_ylabel('Portfolios')\n",
    "\n",
    "# 2. Portfolio Resilience Ranking\n",
    "portfolio_resilience = stress_df.mean(axis=1).sort_values(ascending=False)\n",
    "colors = ['green' if x > -0.05 else 'yellow' if x > -0.10 else 'red' for x in portfolio_resilience]\n",
    "bars = axes[0,1].bar(range(len(portfolio_resilience)), portfolio_resilience, \n",
    "                    color=colors, alpha=0.7)\n",
    "axes[0,1].set_title('Portfolio Resilience Score\\n(Average Stress Test Performance)')\n",
    "axes[0,1].set_ylabel('Average Impact')\n",
    "axes[0,1].set_xticks(range(len(portfolio_resilience)))\n",
    "axes[0,1].set_xticklabels(portfolio_resilience.index, rotation=45)\n",
    "axes[0,1].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[0,1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Scenario Impact Distribution\n",
    "scenario_severity = stress_df.mean(axis=0).sort_values()\n",
    "bars = axes[1,0].bar(range(len(scenario_severity)), abs(scenario_severity), \n",
    "                    color='red', alpha=0.7)\n",
    "axes[1,0].set_title('Stress Scenario Severity\\n(Average Portfolio Impact)')\n",
    "axes[1,0].set_ylabel('Average Impact (Absolute)')\n",
    "axes[1,0].set_xticks(range(len(scenario_severity)))\n",
    "axes[1,0].set_xticklabels(scenario_severity.index, rotation=45, ha='right')\n",
    "axes[1,0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, abs(scenario_severity)):\n",
    "    axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                  f'{value:.1%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Portfolio Performance Under Stress\n",
    "# Compare best and worst performing portfolios\n",
    "best_portfolio = portfolio_resilience.index[0]\n",
    "worst_portfolio = portfolio_resilience.index[-1]\n",
    "\n",
    "comparison_data = stress_df.loc[[best_portfolio, worst_portfolio]].T\n",
    "comparison_data.plot(kind='bar', ax=axes[1,1], alpha=0.7)\n",
    "axes[1,1].set_title(f'Stress Test Comparison\\n{best_portfolio} vs {worst_portfolio}')\n",
    "axes[1,1].set_ylabel('Impact')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Monte Carlo Risk Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_portfolio_simulation(portfolio_weights, returns, num_simulations=1000, time_horizon=252):\n",
    "    \"\"\"Perform Monte Carlo simulation for portfolio risk analysis\"\"\"\n",
    "    \n",
    "    print(f\"\\nüé≤ Monte Carlo Simulation ({num_simulations:,} simulations, {time_horizon} days)\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Calculate portfolio statistics\n",
    "    portfolio_returns = (returns * portfolio_weights).sum(axis=1)\n",
    "    mean_return = portfolio_returns.mean()\n",
    "    std_return = portfolio_returns.std()\n",
    "    \n",
    "    # Run Monte Carlo simulations\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    simulations = []\n",
    "    \n",
    "    for i in range(num_simulations):\n",
    "        # Generate random returns\n",
    "        random_returns = np.random.normal(mean_return, std_return, time_horizon)\n",
    "        \n",
    "        # Calculate cumulative performance\n",
    "        cumulative_returns = np.cumprod(1 + random_returns)\n",
    "        final_value = cumulative_returns[-1]\n",
    "        \n",
    "        # Calculate drawdown\n",
    "        running_max = np.maximum.accumulate(cumulative_returns)\n",
    "        drawdowns = (cumulative_returns - running_max) / running_max\n",
    "        max_drawdown = np.min(drawdowns)\n",
    "        \n",
    "        simulations.append({\n",
    "            'final_value': final_value,\n",
    "            'total_return': final_value - 1,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'path': cumulative_returns\n",
    "        })\n",
    "    \n",
    "    # Analyze simulation results\n",
    "    final_values = [sim['final_value'] for sim in simulations]\n",
    "    total_returns = [sim['total_return'] for sim in simulations]\n",
    "    max_drawdowns = [sim['max_drawdown'] for sim in simulations]\n",
    "    \n",
    "    # Calculate risk metrics\n",
    "    var_95 = np.percentile(total_returns, 5)\n",
    "    var_99 = np.percentile(total_returns, 1)\n",
    "    cvar_95 = np.mean([r for r in total_returns if r <= var_95])\n",
    "    \n",
    "    prob_loss = len([r for r in total_returns if r < 0]) / len(total_returns)\n",
    "    prob_large_loss = len([r for r in total_returns if r < -0.20]) / len(total_returns)\n",
    "    \n",
    "    results = {\n",
    "        'mean_return': np.mean(total_returns),\n",
    "        'std_return': np.std(total_returns),\n",
    "        'var_95': var_95,\n",
    "        'var_99': var_99,\n",
    "        'cvar_95': cvar_95,\n",
    "        'prob_loss': prob_loss,\n",
    "        'prob_large_loss': prob_large_loss,\n",
    "        'mean_max_drawdown': np.mean(max_drawdowns),\n",
    "        'worst_drawdown': np.min(max_drawdowns),\n",
    "        'simulations': simulations\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run Monte Carlo simulation for best portfolio\n",
    "best_portfolio_name = portfolio_risk_analysis['Sharpe Ratio'].idxmax()\n",
    "best_weights = risk_portfolios[best_portfolio_name]\n",
    "\n",
    "if len(best_weights) != len(asset_symbols):\n",
    "    best_weights = best_weights[:len(asset_symbols)]\n",
    "    best_weights = best_weights / best_weights.sum()\n",
    "\n",
    "mc_results = monte_carlo_portfolio_simulation(best_weights, asset_returns, \n",
    "                                            num_simulations=5000, time_horizon=252)\n",
    "\n",
    "print(f\"\\nMonte Carlo Results for {best_portfolio_name} Portfolio:\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"Expected Return (1 year): {mc_results['mean_return']:.2%}\")\n",
    "print(f\"Return Volatility: {mc_results['std_return']:.2%}\")\n",
    "print(f\"VaR (95%): {mc_results['var_95']:.2%}\")\n",
    "print(f\"VaR (99%): {mc_results['var_99']:.2%}\")\n",
    "print(f\"CVaR (95%): {mc_results['cvar_95']:.2%}\")\n",
    "print(f\"Probability of Loss: {mc_results['prob_loss']:.1%}\")\n",
    "print(f\"Probability of >20% Loss: {mc_results['prob_large_loss']:.1%}\")\n",
    "print(f\"Average Max Drawdown: {mc_results['mean_max_drawdown']:.2%}\")\n",
    "print(f\"Worst Case Drawdown: {mc_results['worst_drawdown']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Monte Carlo results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Return Distribution\n",
    "total_returns = [sim['total_return'] for sim in mc_results['simulations']]\n",
    "axes[0,0].hist(total_returns, bins=50, alpha=0.7, color='blue', density=True)\n",
    "axes[0,0].axvline(mc_results['var_95'], color='red', linestyle='--', \n",
    "                 label=f'VaR 95%: {mc_results[\"var_95\"]:.1%}')\n",
    "axes[0,0].axvline(mc_results['var_99'], color='darkred', linestyle='--', \n",
    "                 label=f'VaR 99%: {mc_results[\"var_99\"]:.1%}')\n",
    "axes[0,0].axvline(mc_results['mean_return'], color='green', linestyle='-', \n",
    "                 label=f'Expected: {mc_results[\"mean_return\"]:.1%}')\n",
    "axes[0,0].set_title(f'Return Distribution\\n{best_portfolio_name} Portfolio (1 Year)')\n",
    "axes[0,0].set_xlabel('Total Return')\n",
    "axes[0,0].set_ylabel('Density')\n",
    "axes[0,0].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0%}'))\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Sample Portfolio Paths\n",
    "sample_paths = [sim['path'] for sim in mc_results['simulations'][:100]]  # Show 100 paths\n",
    "for path in sample_paths:\n",
    "    axes[0,1].plot(path, alpha=0.1, color='blue')\n",
    "\n",
    "# Add percentile paths\n",
    "all_paths = np.array([sim['path'] for sim in mc_results['simulations']])\n",
    "percentile_5 = np.percentile(all_paths, 5, axis=0)\n",
    "percentile_50 = np.percentile(all_paths, 50, axis=0)\n",
    "percentile_95 = np.percentile(all_paths, 95, axis=0)\n",
    "\n",
    "axes[0,1].plot(percentile_5, color='red', linewidth=2, label='5th Percentile')\n",
    "axes[0,1].plot(percentile_50, color='green', linewidth=2, label='Median')\n",
    "axes[0,1].plot(percentile_95, color='blue', linewidth=2, label='95th Percentile')\n",
    "\n",
    "axes[0,1].set_title('Monte Carlo Portfolio Paths\\n(100 sample paths + percentiles)')\n",
    "axes[0,1].set_xlabel('Trading Days')\n",
    "axes[0,1].set_ylabel('Portfolio Value')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Maximum Drawdown Distribution\n",
    "max_drawdowns = [sim['max_drawdown'] for sim in mc_results['simulations']]\n",
    "axes[1,0].hist(max_drawdowns, bins=50, alpha=0.7, color='red', density=True)\n",
    "axes[1,0].axvline(mc_results['mean_max_drawdown'], color='darkred', linestyle='-', \n",
    "                 label=f'Average: {mc_results[\"mean_max_drawdown\"]:.1%}')\n",
    "axes[1,0].axvline(mc_results['worst_drawdown'], color='black', linestyle='--', \n",
    "                 label=f'Worst Case: {mc_results[\"worst_drawdown\"]:.1%}')\n",
    "axes[1,0].set_title('Maximum Drawdown Distribution')\n",
    "axes[1,0].set_xlabel('Maximum Drawdown')\n",
    "axes[1,0].set_ylabel('Density')\n",
    "axes[1,0].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0%}'))\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Risk Metrics Summary\n",
    "risk_metrics = {\n",
    "    'Prob of Loss': mc_results['prob_loss'],\n",
    "    'Prob of >20% Loss': mc_results['prob_large_loss'],\n",
    "    'VaR 95%': abs(mc_results['var_95']),\n",
    "    'VaR 99%': abs(mc_results['var_99']),\n",
    "    'CVaR 95%': abs(mc_results['cvar_95'])\n",
    "}\n",
    "\n",
    "metrics_names = list(risk_metrics.keys())\n",
    "metrics_values = list(risk_metrics.values())\n",
    "colors = ['red' if 'Loss' in name else 'orange' for name in metrics_names]\n",
    "\n",
    "bars = axes[1,1].bar(metrics_names, metrics_values, color=colors, alpha=0.7)\n",
    "axes[1,1].set_title('Risk Metrics Summary')\n",
    "axes[1,1].set_ylabel('Probability / Risk Level')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1%}'))\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, metrics_values):\n",
    "    axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                  f'{value:.1%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Risk Analysis Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\nprint(\"QUANTUMEDGE COMPREHENSIVE RISK ANALYSIS SUMMARY\")\nprint(\"=\"*70)\n\n# Generate comprehensive insights\nprint(\"\\nüéØ KEY RISK INSIGHTS\")\nprint(\"-\" * 20)\n\ninsights = [\n    f\"üìä Analyzed {len(asset_symbols)} assets across {len(returns)} trading days\",\n    f\"üèÜ Best risk-adjusted portfolio: {portfolio_risk_analysis['Sharpe Ratio'].idxmax()} (Sharpe: {portfolio_risk_analysis['Sharpe Ratio'].max():.3f})\",\n    f\"üõ°Ô∏è Lowest risk portfolio: {portfolio_risk_analysis['Annual Volatility'].idxmin()} (Vol: {portfolio_risk_analysis['Annual Volatility'].min():.2%})\",\n    f\"üìâ Lowest drawdown risk: {portfolio_risk_analysis.nsmallest(1, lambda x: abs(x['Max Drawdown'])).index[0]}\",\n    f\"‚ö†Ô∏è Highest concentration risk: {portfolio_risk_analysis['Max Weight'].idxmax()} ({portfolio_risk_analysis['Max Weight'].max():.1%} max weight)\",\n    f\"üé≤ Monte Carlo analysis shows {mc_results['prob_loss']:.1%} probability of loss over 1 year\"\n]\n\nfor insight in insights:\n    print(insight)\n\nprint(\"\\nüìà RISK FRAMEWORK RECOMMENDATIONS\")\nprint(\"-\" * 35)\n\nrecommendations = {\n    \"Level 1 - Basic Monitoring\": [\n        \"‚Ä¢ Track daily volatility and beta for all positions\",\n        \"‚Ä¢ Monitor correlation changes during market stress\",\n        \"‚Ä¢ Set alerts for Sharpe ratio deterioration\",\n        \"‚Ä¢ Review tracking error vs benchmark monthly\"\n    ],\n    \"Level 2 - Distribution Analysis\": [\n        \"‚Ä¢ Calculate VaR and CVaR daily for tail risk management\",\n        \"‚Ä¢ Monitor skewness and kurtosis for distribution changes\",\n        \"‚Ä¢ Track downside deviation separately from total volatility\",\n        \"‚Ä¢ Implement scenario-based stress testing weekly\"\n    ],\n    \"Level 3 - Advanced Risk Management\": [\n        \"‚Ä¢ Monitor maximum drawdown and recovery patterns\",\n        \"‚Ä¢ Track Calmar and Sortino ratios for risk-adjusted performance\",\n        \"‚Ä¢ Analyze upside/downside capture ratios vs benchmark\",\n        \"‚Ä¢ Implement dynamic risk budgeting based on volatility regimes\"\n    ],\n    \"Level 4 - Portfolio Construction\": [\n        \"‚Ä¢ Use risk contribution analysis for position sizing\",\n        \"‚Ä¢ Implement concentration limits (max 20% single position)\",\n        \"‚Ä¢ Diversify across effective number of assets (target >5)\",\n        \"‚Ä¢ Consider alternative objectives (CVaR, Calmar) for different market conditions\"\n    ],\n    \"Level 5 - Institutional Risk Management\": [\n        \"‚Ä¢ Conduct monthly Monte Carlo simulations (5,000+ paths)\",\n        \"‚Ä¢ Implement comprehensive stress testing framework\",\n        \"‚Ä¢ Monitor regime changes and correlation breakdowns\",\n        \"‚Ä¢ Establish dynamic hedging strategies for tail risk protection\"\n    ]\n}\n\nfor level, items in recommendations.items():\n    print(f\"\\n{level}:\")\n    for item in items:\n        print(f\"  {item}\")\n\nprint(\"\\nüîß IMPLEMENTATION ROADMAP\")\nprint(\"-\" * 25)\n\nroadmap = [\n    \"Phase 1 (Week 1-2): Implement basic risk monitoring dashboard\",\n    \"Phase 2 (Week 3-4): Add VaR/CVaR calculations and distribution analysis\",\n    \"Phase 3 (Month 2): Implement advanced risk metrics and drawdown monitoring\",\n    \"Phase 4 (Month 3): Add portfolio risk decomposition and attribution\",\n    \"Phase 5 (Month 4): Deploy stress testing and Monte Carlo frameworks\",\n    \"Phase 6 (Ongoing): Continuous monitoring and model validation\"\n]\n\nfor i, phase in enumerate(roadmap, 1):\n    print(f\"{i}. {phase}\")\n\nprint(\"\\n‚ö° QUANTUMEDGE ADVANTAGES\")\nprint(\"-\" * 25)\n\nadvantages = [\n    \"üî¨ Advanced Objectives: CVaR, Sortino, and Calmar optimization for sophisticated risk management\",\n    \"üéØ Multi-Level Analysis: From basic volatility to complex tail risk measures\",\n    \"üìä Real-Time Monitoring: Dynamic risk dashboard with automated alerts\",\n    \"üé≤ Stress Testing: Comprehensive scenario analysis and Monte Carlo simulation\",\n    \"‚öñÔ∏è Risk Attribution: Detailed contribution analysis for informed decision-making\",\n    \"üîÑ Adaptive Strategies: Dynamic optimization based on changing market conditions\"\n]\n\nfor advantage in advantages:\n    print(advantage)\n\nprint(\"\\nüéâ RISK ANALYSIS COMPLETE\")\nprint(\"-\" * 25)\nprint(f\"‚úÖ Analyzed {len(risk_portfolios)} portfolios across {len(RISK_UNIVERSE)} risk factors\")\nprint(f\"‚úÖ Generated {len(stress_test_results)} stress test scenarios\")\nprint(f\"‚úÖ Performed {5000:,} Monte Carlo simulations\")\nprint(f\"‚úÖ Created comprehensive risk monitoring framework\")\nprint(f\"‚úÖ Provided actionable risk management recommendations\")\n\nprint(\"\\nüìö Continue your QuantumEdge journey:\")\nprint(\"‚Ä¢ Review Tutorial 1-4 for optimization strategies\")\nprint(\"‚Ä¢ Implement real-time monitoring using QuantumEdge APIs\")\nprint(\"‚Ä¢ Explore custom risk objectives for your specific needs\")\nprint(\"‚Ä¢ Deploy automated rebalancing with risk constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This comprehensive risk analysis tutorial demonstrates the full power of QuantumEdge's risk management capabilities, providing a complete framework for modern portfolio risk analysis.\n",
    "\n",
    "### **Technical Achievement**\n",
    "\n",
    "**5-Level Risk Framework Implementation**:\n",
    "1. **Basic Risk Metrics** - Volatility, beta, Sharpe ratios, and correlation analysis\n",
    "2. **Distribution-Based Risk** - VaR, CVaR, skewness, kurtosis, and tail risk measures\n",
    "3. **Advanced Risk Measures** - Drawdown analysis, recovery patterns, and capture ratios\n",
    "4. **Risk Decomposition** - Asset contribution analysis and portfolio concentration metrics\n",
    "5. **Stress Testing** - Scenario analysis, Monte Carlo simulation, and regime analysis\n",
    "\n",
    "### **Practical Applications**\n",
    "\n",
    "**For Institutional Risk Management**:\n",
    "- Regulatory compliance with VaR and stress testing requirements\n",
    "- Dynamic risk budgeting and allocation frameworks\n",
    "- Real-time monitoring and automated alerting systems\n",
    "- Comprehensive reporting for risk committees and regulators\n",
    "\n",
    "**For Portfolio Managers**:\n",
    "- Risk-adjusted performance measurement and attribution\n",
    "- Position sizing based on risk contribution analysis\n",
    "- Stress testing for scenario planning and hedging decisions\n",
    "- Dynamic optimization using alternative risk objectives\n",
    "\n",
    "**For Individual Investors**:\n",
    "- Understanding portfolio risk characteristics beyond simple volatility\n",
    "- Monitoring drawdown patterns and recovery potential\n",
    "- Stress testing personal portfolios against various market scenarios\n",
    "- Making informed decisions about risk tolerance and investment objectives\n",
    "\n",
    "### **Key Innovations**\n",
    "\n",
    "1. **Multi-Objective Risk Optimization** - Beyond mean-variance to CVaR, Sortino, and Calmar objectives\n",
    "2. **Comprehensive Risk Dashboard** - Real-time monitoring with automated alerts and regime detection\n",
    "3. **Advanced Stress Testing** - Scenario analysis with portfolio-specific impact assessment\n",
    "4. **Monte Carlo Risk Analysis** - Statistical simulation for probability-based risk assessment\n",
    "5. **Risk Attribution Framework** - Detailed contribution analysis for informed portfolio construction\n",
    "\n",
    "### **Implementation Value**\n",
    "\n",
    "This tutorial provides a complete blueprint for implementing enterprise-grade risk management systems. The combination of QuantumEdge's optimization capabilities with comprehensive risk analysis creates a powerful platform for:\n",
    "\n",
    "- **Evidence-Based Decision Making** - All risk metrics backed by rigorous mathematical foundations\n",
    "- **Proactive Risk Management** - Early warning systems and automated monitoring\n",
    "- **Regulatory Compliance** - Meet institutional risk management requirements\n",
    "- **Performance Enhancement** - Risk-adjusted optimization for superior long-term results\n",
    "\n",
    "The framework scales from individual portfolios to institutional asset management, providing the tools necessary for sophisticated risk management in today's complex financial markets.\n",
    "\n",
    "---\n",
    "\n",
    "**QuantumEdge Tutorial Series Complete**\n",
    "\n",
    "You have now completed the comprehensive QuantumEdge tutorial series, covering:\n",
    "1. **Getting Started** - Basic optimization and setup\n",
    "2. **Quantum vs Classical** - Comparative algorithm analysis\n",
    "3. **Backtesting Strategies** - Historical performance validation\n",
    "4. **Advanced Objectives** - CVaR, Sortino, and Calmar optimization\n",
    "5. **Risk Analysis** - Comprehensive risk management framework\n",
    "\n",
    "The knowledge and tools provided enable you to build sophisticated, quantum-inspired portfolio optimization systems with enterprise-grade risk management capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}